---
title: "R Notebook"
output: html_notebook
---
Este Script fue elaborado de manera colaborativa e igualitaria por Valeria Soldevilla, Mariano Diaz, Gianella Seclen y Jesus Zarate.


PRIMERA SELECCION Variables
Dependiente: Proporción de curules ocupados por mujeres en parlamentos nacionales (%)


Independientes
1.	Educación: - 
a.	Inscripción en educación terciaria, mujeres (%)
b.	Inscripción en educación secundaria, mujeres (%)
2.	empleabilidad / economía 
a.	Poblacion empleada ratio 15+, mujeres (%)
b.	Ratio de mujeres a hombres en fuerza de trabajo (%)
c.	Empleo vulnerable, mujeres (% de empleo mujeres)  


Por cada variable se toman en cuenta los últimos 15 años, separados en lustros: 2005-2009 , 2010-2014 , 2015-2019. (promedio de años por lustro)

Educacion secundaria % mujeres 
```{r}
library(rio)
educacionxlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/secondaryy.xlsx"
secondary=import(educacionxlsx)
secondary[,c(1,2,4)] = NULL

secondary[,c(2:16)]=lapply(secondary[,c(2:16)],as.numeric)

secondary$"educacion secundaria lustro 1" = rowMeans(secondary[, 2:6], na.rm=TRUE)
secondary$"educacion secundaria lustro 2" = rowMeans(secondary[, 7:11], na.rm=TRUE)
secondary$"educacion secundaria lustro 3" = rowMeans(secondary[, 12:16], na.rm=TRUE)


secondary[,-c(1,17,18,19)] = NULL

secondary[,4]= replace(secondary[,4], secondary[,4] == "NaN",NA)
secondary[,3]= replace(secondary[,3], secondary[,3] == "NaN",NA)
secondary[,2]= replace(secondary[,2], secondary[,2] == "NaN",NA)

names(secondary) = c("Pais","edusecM1","edusecM2","edusecM3")

Secundaria=secondary[c(1:263),]

```

empleo vulnerable % mujeres
```{r}
vulnerablexlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/vulnerable.xlsx"
vulnerable=import(vulnerablexlsx)
vulnerable[,c(1,2,4)] = NULL
vulnerable[,c(2:16)]=lapply(vulnerable[,c(2:16)],as.numeric)

vulnerable$"empleo vulnerable lustro 1" = rowMeans(vulnerable[, 2:6], na.rm=TRUE)
vulnerable$"empleo vulnerable lustro 2" = rowMeans(vulnerable[, 7:11], na.rm=TRUE)
vulnerable$"empleo vulnerable lustro 3" = rowMeans(vulnerable[, 12:16], na.rm=TRUE)

vulnerable[,-c(1,17,18,19)] = NULL

vulnerable[,4]= replace(vulnerable[,4], vulnerable[,4] == "NaN",NA)
vulnerable[,3]= replace(vulnerable[,3], vulnerable[,3] == "NaN",NA)
vulnerable[,2]= replace(vulnerable[,2], vulnerable[,2] == "NaN",NA)

names(vulnerable) = c("Pais","vulM1","vulM2","vulM3")
EmpleoVulnerable=vulnerable[c(1:263),]
```


Dependiente: % curules ocupados por mujeres en el parlamento 
```{r}
library(rio)
Data1="https://github.com/valese-m/propuesta-proyecto-/raw/master/parliament.xlsx"
Depend=import(Data1)
Depend[,-c(3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19)]=NULL

Dependiente1=Depend[c(1:263),]

Dependiente1[(2:16)]=lapply(Dependiente1[(2:16)], as.numeric)

Dependiente1$"parlamento lustro 1" = rowMeans(Dependiente1[, 2:6], na.rm=TRUE)
Dependiente1$"parlamento lustro 2" = rowMeans(Dependiente1[, 7:11], na.rm=TRUE)
Dependiente1$"parlamento lustro 3" = rowMeans(Dependiente1[, 12:16], na.rm=TRUE)

Dependiente1[,-c(1,17,18,19)]=NULL

Dependiente1[,c(2:4)]= replace(Dependiente1[,c(2:4)], 
                               Dependiente1[,c(2:4)] == "NaN",NA)

names(Dependiente1) = c("Pais","deparla1","deparla2","deparla3")
```

Variable: empleo mujeres
```{r}
library(rio)
Employmentgithub="https://github.com/valese-m/propuesta-proyecto-/raw/master/employment.xlsx"
Employment=import(Employmentgithub)

Employment[,c(1,2,4)] = NULL

Employment[,c(2:16)]=lapply(Employment[,c(2:16)],as.numeric)

Employment$"empleoM1" = rowMeans(Employment[, 2:6], na.rm=TRUE)
Employment$"empleoM2" = rowMeans(Employment[, 7:11], na.rm=TRUE)
Employment$"empleoM3" = rowMeans(Employment[, 12:16], na.rm=TRUE)

Employment[,-c(1,17,18,19)] = NULL

Employment[,4]= replace(Employment[,4], Employment[,4] == "NaN",NA)
Employment[,3]= replace(Employment[,3], Employment[,3] == "NaN",NA)
Employment[,2]= replace(Employment[,2], Employment[,2] == "NaN",NA)

colnames(Employment)[1]="Pais"

Empleo=Employment[c(1:263),]
```


Variable: fuerza de trabajo
Ratio of female to male labor force participation rate (%) (modeled ILO estimate) 
```{r}
library(rio)
Laborgithub="https://github.com/valese-m/propuesta-proyecto-/raw/master/labor.xlsx"
Labor=import(Laborgithub)

Labor[,c(1,2,4)] = NULL

Labor[,c(2:16)]=lapply(Labor[,c(2:16)],as.numeric)

Labor$"Labor lustro 1" = rowMeans(Labor[, 2:6], na.rm=TRUE)
Labor$"Labor lustro 2" = rowMeans(Labor[, 7:11], na.rm=TRUE)
Labor$"Labor lustro 3" = rowMeans(Labor[, 12:16], na.rm=TRUE)

Labor[,-c(1,17,18,19)] = NULL

Labor[,4]= replace(Labor[,4], Labor[,4] == "NaN",NA)
Labor[,3]= replace(Labor[,3], Labor[,3] == "NaN",NA)
Labor[,2]= replace(Labor[,2], Labor[,2] == "NaN",NA)

names(Labor) = c("Pais","labor1","labor2","labor3")

FuerzaLaboral=Labor[c(1:263),]
```


Variable: educacion terciaria 
```{r}
linktertiary="https://github.com/valese-m/propuesta-proyecto-/raw/master/tertiary.xlsx"
tertiary=import(linktertiary)
tertiary[,c(1,2,4)] = NULL
tertiary[,c(2:16)]=lapply(tertiary[,c(2:16)],as.numeric)

tertiary$"educacion terciaria lustro 1" = rowMeans(tertiary[, 2:6], na.rm=TRUE)
tertiary$"educacion terciaria lustro 2" = rowMeans(tertiary[, 7:11], na.rm=TRUE)
tertiary$"educacion terciaria lustro 3" = rowMeans(tertiary[, 12:16], na.rm=TRUE)

tertiary[,-c(1,17,18,19)] = NULL

tertiary[,4]= replace(tertiary[,4], tertiary[,4] == "NaN",NA)
tertiary[,3]= replace(tertiary[,3], tertiary[,3] == "NaN",NA)
tertiary[,2]= replace(tertiary[,2], tertiary[,2] == "NaN",NA)

names(tertiary) = c("Pais","eduterM1","eduterM2","eduterM3")

Terciario=tertiary[c(1:263),]
```

MERGE PRIMERA SELECCION DE VARIABLES
```{r}
Dataedu=merge(Secundaria,Terciario, by.x = 'Pais', by.y = 'Pais')
Dataempleo1=merge(Empleo, FuerzaLaboral,by.x = 'Pais', by.y = 'Pais')
Dataempleo2=merge(Dataempleo1, EmpleoVulnerable,by.x = 'Pais', by.y = 'Pais')
DataInd=merge(Dataempleo2, Dataedu,by.x = 'Pais', by.y = 'Pais')
Datatotal=merge(Dependiente1, DataInd,by.x = 'Pais', by.y = 'Pais')

names(Datatotal) = c("Pais","deparla1","deparla2","dparla3", "empleoM1", "empleoM2","empleoM3", 
                     "labor1", "labor2", "labor3", "vulM1", "vulM2", "vulM3", "edusecM1", "edusecM2",
                     "edusecM3", "eduterM1", "eduterM2", "eduterM3")
```

eliminando filas que no son paises 
```{r}
DataPaises<-Datatotal[-c(4,8,38, 39,41,61,62,63,64,73,74,75,76,77,78,81,91,99,
                         100,104,106,107,108,109,115,126,130,131,132,133,135,142,
                       143,144,158,159,160,161,180,182,184,185,195,196, 214,
                       219,225,227,228,229,245, 252, 260), ]
```

PRIMERA SELECCION DE VARIABLES: VARIABLES HOMBRES 

EMPLEO % HOMBRES
```{r}
library(rio)
employmentmalexlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/employmentmale.xlsx"
empleohombre=import(employmentmalexlsx)
empleohombre[,c(1,2,4)] = NULL

empleohombre[,c(2:16)]=lapply(empleohombre[,c(2:16)],as.numeric)

empleohombre$"empleoH1" = rowMeans(empleohombre[, 2:6], na.rm=TRUE)
empleohombre$"empleoH2" = rowMeans(empleohombre[, 7:11], na.rm=TRUE)
empleohombre$"empleoH3" = rowMeans(empleohombre[, 12:16], na.rm=TRUE)

empleohombre[,-c(1,17,18,19)] = NULL

empleohombre[,4]= replace(empleohombre[,4], empleohombre[,4] == "NaN",NA)
empleohombre[,3]= replace(empleohombre[,3], empleohombre[,3] == "NaN",NA)
empleohombre[,2]= replace(empleohombre[,2], empleohombre[,2] == "NaN",NA)

names(empleohombre)[names(empleohombre)=="Country Name"]="Pais"

EmpleoH=empleohombre[c(1:217),]
```


secundaria % HOMBRES
```{r}
library(rio)
secondarymalexlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/secondarymale.xlsx"
secondarymale=import(secondarymalexlsx)
secondarymale[,c(1,2,4)] = NULL

secondarymale[,c(2:16)]=lapply(secondarymale[,c(2:16)],as.numeric)

secondarymale$"edusecH1" = rowMeans(secondarymale[, 2:6], na.rm=TRUE)
secondarymale$"edusecH2" = rowMeans(secondarymale[, 7:11], na.rm=TRUE)
secondarymale$"edusecH3" = rowMeans(secondarymale[, 12:16], na.rm=TRUE)

secondarymale[,-c(1,17,18,19)] = NULL

secondarymale[,4]= replace(secondarymale[,4], secondarymale[,4] == "NaN",NA)
secondarymale[,3]= replace(secondarymale[,3], secondarymale[,3] == "NaN",NA)
secondarymale[,2]= replace(secondarymale[,2], secondarymale[,2] == "NaN",NA)

names(secondarymale)[names(secondarymale)=="Country Name"]="Pais"

SecundariaH=secondarymale[c(1:217),]
```



terciaria % HOMBRES
```{r}
library(rio)
tertiarymalexlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/tertiarymale.xlsx"
tertiarymale=import(tertiarymalexlsx)
tertiarymale[,c(1,2,4)] = NULL

tertiarymale[,c(2:16)]=lapply(tertiarymale[,c(2:16)],as.numeric)

tertiarymale$"eduterH1" = rowMeans(tertiarymale[, 2:6], na.rm=TRUE)
tertiarymale$"eduterH2" = rowMeans(tertiarymale[, 7:11], na.rm=TRUE)
tertiarymale$"eduterH3" = rowMeans(tertiarymale[, 12:16], na.rm=TRUE)


tertiarymale[,-c(1,17,18,19)] = NULL

tertiarymale[,4]= replace(tertiarymale[,4], tertiarymale[,4] == "NaN",NA)
tertiarymale[,3]= replace(tertiarymale[,3], tertiarymale[,3] == "NaN",NA)
tertiarymale[,2]= replace(tertiarymale[,2], tertiarymale[,2] == "NaN",NA)

names(tertiarymale)[names(tertiarymale)=="Country Name"]="Pais"

TerciariaH=tertiarymale[c(1:217),]
```


empleo vulnerable % HOMBRES
```{r}
library(rio)
vulnerablexlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/vulnerablemale.xlsx"
vulnerablemale=import(vulnerablexlsx)
vulnerablemale[,c(1,2,4)] = NULL

vulnerablemale[,c(2:16)]=lapply(vulnerablemale[,c(2:16)],as.numeric)

vulnerablemale$"vulH1" = rowMeans(vulnerablemale[, 2:6], na.rm=TRUE)
vulnerablemale$"vulH2" = rowMeans(vulnerablemale[, 7:11], na.rm=TRUE)
vulnerablemale$"vulH3" = rowMeans(vulnerablemale[, 12:16], na.rm=TRUE)

vulnerablemale[,-c(1,17,18,19)] = NULL

vulnerablemale[,4]= replace(vulnerablemale[,4], vulnerablemale[,4] == "NaN",NA)
vulnerablemale[,3]= replace(vulnerablemale[,3], vulnerablemale[,3] == "NaN",NA)
vulnerablemale[,2]= replace(vulnerablemale[,2], vulnerablemale[,2] == "NaN",NA)

names(vulnerablemale)[names(vulnerablemale)=="Country Name"]="Pais"

VulnerableH=vulnerablemale[c(1:217),]
```

Merge variables de hombres
```{r}
DataeduH=merge(SecundariaH,TerciariaH, by.x = 'Pais', by.y = 'Pais')
Dataempleo1H=merge(VulnerableH, EmpleoH,by.x = 'Pais', by.y = 'Pais')
DataHombres=merge(DataeduH, Dataempleo1H,by.x = 'Pais', by.y = 'Pais')

```


SEGUNDA SELECCION DE VARIABLES
SECUNDARIA GP
GENDER PARITY INDEX
```{r}
library(rio)
secondarygpxlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/secondary2.xlsx"
secondarygp=import(secondarygpxlsx)
secondarygp[,c(1,2,4)] = NULL

secondarygp[,c(2:16)]=lapply(secondarygp[,c(2:16)],as.numeric)

secondarygp$"edusecGP1" = rowMeans(secondarygp[, 2:6], na.rm=TRUE)
secondarygp$"edusecGP2" = rowMeans(secondarygp[, 7:11], na.rm=TRUE)
secondarygp$"edusecGP3" = rowMeans(secondarygp[, 12:16], na.rm=TRUE)

secondarygp[,-c(1,17,18,19)] = NULL

secondarygp[,4]= replace(secondarygp[,4], secondarygp[,4] == "NaN",NA)
secondarygp[,3]= replace(secondarygp[,3], secondarygp[,3] == "NaN",NA)
secondarygp[,2]= replace(secondarygp[,2], secondarygp[,2] == "NaN",NA)

names(secondarygp)[names(secondarygp)=="Country Name"]="Pais"

secundariaGP=secondarygp[c(1:217),]
```



TERCIARIA GP
```{r}
library(rio)
tertiarygpxlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/tertiary2.xlsx"
tertiarygp=import(tertiarygpxlsx)
tertiarygp[,c(1,2,4)] = NULL

tertiarygp[,c(2:16)]=lapply(tertiarygp[,c(2:16)],as.numeric)

tertiarygp$"eduterGP1" = rowMeans(tertiarygp[, 2:6], na.rm=TRUE)
tertiarygp$"eduterGP2" = rowMeans(tertiarygp[, 7:11], na.rm=TRUE)
tertiarygp$"eduterGP3" = rowMeans(tertiarygp[, 12:16], na.rm=TRUE)

tertiarygp[,-c(1,17,18,19)] = NULL

tertiarygp[,4]= replace(tertiarygp[,4], tertiarygp[,4] == "NaN",NA)
tertiarygp[,3]= replace(tertiarygp[,3], tertiarygp[,3] == "NaN",NA)
tertiarygp[,2]= replace(tertiarygp[,2], tertiarygp[,2] == "NaN",NA)

names(tertiarygp)[names(tertiarygp)=="Country Name"]="Pais"

terciariaGP=tertiarygp[c(1:217),]
```

merge de gender parity
```{r}
DataeduGP=merge(secundariaGP,terciariaGP, by.x = 'Pais', by.y = 'Pais')
```




VARIABLES DE OPINION
OPINION: contrato
```{r}
library(rio)
contratoxlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/opicontrato.xlsx"
opicon=import(contratoxlsx)
opicon[,c(1,2,4)] = NULL

opicon[,c(2:16)]=lapply(opicon[,c(2:16)],as.numeric)

opicon$"opicon1" = rowMeans(opicon[, 2:6], na.rm=TRUE)
opicon$"opicon2" = rowMeans(opicon[, 7:11], na.rm=TRUE)
opicon$"opicon3" = rowMeans(opicon[, 12:16], na.rm=TRUE)


opicon[,-c(1,17,18,19)] = NULL

opicon[,4]= replace(opicon[,4], opicon[,4] == "NaN",NA)
opicon[,3]= replace(opicon[,3], opicon[,3] == "NaN",NA)
opicon[,2]= replace(opicon[,2], opicon[,2] == "NaN",NA)

names(opicon)[names(opicon)=="Country Name"]="Pais"

opicontrato=opicon[c(1:217),]
```


OPINION: negocio
```{r}
library(rio)
negocioxlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/opinegocio.xlsx"
opinego=import(negocioxlsx)
opinego[,c(1,2,4)] = NULL

opinego[,c(2:16)]=lapply(opinego[,c(2:16)],as.numeric)

opinego$"opinego1" = rowMeans(opinego[, 2:6], na.rm=TRUE)
opinego$"opinego2" = rowMeans(opinego[, 7:11], na.rm=TRUE)
opinego$"opinego3" = rowMeans(opinego[, 12:16], na.rm=TRUE)


opinego[,-c(1,17,18,19)] = NULL

opinego[,4]= replace(opinego[,4], opinego[,4] == "NaN",NA)
opinego[,3]= replace(opinego[,3], opinego[,3] == "NaN",NA)
opinego[,2]= replace(opinego[,2], opinego[,2] == "NaN",NA)

names(opinego)[names(opinego)=="Country Name"]="Pais"

opinegocio=opinego[c(1:217),]
```


OPINION: cuenta bancaria
```{r}
library(rio)
bancoxlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/opibanco.xlsx"
opibanco=import(bancoxlsx)
opibanco[,c(1,2,4)] = NULL

opibanco[,c(2:16)]=lapply(opibanco[,c(2:16)],as.numeric)

opibanco$"opibanco1" = rowMeans(opibanco[, 2:6], na.rm=TRUE)
opibanco$"opibanco2" = rowMeans(opibanco[, 7:11], na.rm=TRUE)
opibanco$"opibanco3" = rowMeans(opibanco[, 12:16], na.rm=TRUE)

opibanco[,-c(1,17,18,19)] = NULL

opibanco[,4]= replace(opibanco[,4], opibanco[,4] == "NaN",NA)
opibanco[,3]= replace(opibanco[,3], opibanco[,3] == "NaN",NA)
opibanco[,2]= replace(opibanco[,2], opibanco[,2] == "NaN",NA)

names(opibanco)[names(opibanco)=="Country Name"]="Pais"

opicuenta=opibanco[c(1:217),]
```


OPINION: trabajo
```{r}
library(rio)
otrabajoxlsx="https://github.com/valese-m/propuesta-proyecto-/raw/master/opiniontrabajo.xlsx"
opitraba=import(otrabajoxlsx)
opitraba[,c(1,2,4)] = NULL

opitraba[,c(2:16)]=lapply(opitraba[,c(2:16)],as.numeric)

opitraba$"opitrabajo1" = rowMeans(opitraba[, 2:6], na.rm=TRUE)
opitraba$"opitrabajo2" = rowMeans(opitraba[, 7:11], na.rm=TRUE)
opitraba$"opitrabajo3" = rowMeans(opitraba[, 12:16], na.rm=TRUE)

opitraba[,-c(1,17,18,19)] = NULL

opitraba[,4]= replace(opitraba[,4], opitraba[,4] == "NaN",NA)
opitraba[,3]= replace(opitraba[,3], opitraba[,3] == "NaN",NA)
opitraba[,2]= replace(opitraba[,2], opitraba[,2] == "NaN",NA)


names(opitraba)[names(opitraba)=="Country Name"]="Pais"

opitrabajo=opitraba[c(1:217),]
```

MERGE VARIABLES OPINION
```{r}
MergeOpi=merge(opitrabajo, opicuenta, by.x = 'Pais', by.y = 'Pais')

MergeOpi2=merge(MergeOpi, opicontrato, by.x = 'Pais', by.y = 'Pais')

OpinionTotal=merge(MergeOpi2, opinegocio, by.x = 'Pais', by.y = 'Pais')
```


RECODIFICACION DE LOS PAISES QUE NO PROMEDIARON UNO
```{r}
which(OpinionTotal == 0.2, arr.ind=TRUE)
which(OpinionTotal == 0.8, arr.ind=TRUE)
which(OpinionTotal == 0.4, arr.ind=TRUE)
which(OpinionTotal == 0.6, arr.ind=TRUE)

## el recode de los numeros que no se promedian a 0 o 1 
#Timor 2012  lustro 2
OpinionTotal[194, 3] = 1 #trabajo 
OpinionTotal[194, 6] = 1 #banco
OpinionTotal[194, 9] = 1 #contrato

#Sierra Leone, Lustro 1 2007, todos 
OpinionTotal[171, 2] = 0
OpinionTotal[171, 5] = 0
OpinionTotal[171, 8] = 0
OpinionTotal[171, 11] = 0


#Congo. Dem. Rep, lustro 3, todos,  2017, 
OpinionTotal[45, 4] = 1
OpinionTotal[45, 7] = 1
OpinionTotal[45, 10] = 1
OpinionTotal[45, 13] = 1

#Lesoto, lustro 1, todos,  2007,
OpinionTotal[112, 2] = 1
OpinionTotal[112, 5] = 1
OpinionTotal[112, 8] = 1
OpinionTotal[112, 11] = 1


#Cote d’Ivoire, lustro 2 trabajo—> 2010 
OpinionTotal[48, 3] = 0 

#Togo, lustro 2 trabajo —> 2013
OpinionTotal[195, 3] = 1

```


```{r}
#Recode de democracia del 1 (MAL) al 4 (BIEN) pero ignorando intermedios. 5 no porque es "No sabe"
OpinionTotal[,c(2:13)]=lapply(OpinionTotal[,c(2:13)],as.factor)

library(dplyr)
OpinionTotal$opitrabajo1=recode(OpinionTotal$opitrabajo1,"1"='si',"0"='no')
OpinionTotal$opitrabajo3=recode(OpinionTotal$opitrabajo3,"1"='si',"0"='no')
OpinionTotal$opitrabajo2=recode(OpinionTotal$opitrabajo2,"1"='si',"0"='no')

OpinionTotal$opibanco1=recode(OpinionTotal$opibanco1,"1"='si',"0"='no')
OpinionTotal$opibanco2=recode(OpinionTotal$opibanco2,"1"='si',"0"='no')
OpinionTotal$opibanco3=recode(OpinionTotal$opibanco3,"1"='si',"0"='no')

OpinionTotal$opicon1=recode(OpinionTotal$opicon1,"1"='si',"0"='no')
OpinionTotal$opicon2=recode(OpinionTotal$opicon2,"1"='si',"0"='no')
OpinionTotal$opicon3=recode(OpinionTotal$opicon3,"1"='si',"0"='no')

OpinionTotal$opinego1=recode(OpinionTotal$opinego1,"1"='si',"0"='no')
OpinionTotal$opinego2=recode(OpinionTotal$opinego2,"1"='si',"0"='no')
OpinionTotal$opinego3=recode(OpinionTotal$opinego3,"1"='si',"0"='no')

```

Merge de datas mujeres vs hombres 
```{r}
MergeTotalHM=merge(DataInd, DataHombres,by.x = 'Pais', by.y = 'Pais')

MergeTotalHM=na.omit(MergeTotalHM)

##PRUEBA FUNCIONA
MergeTotalHM <- transform(MergeTotalHM, sec1 = edusecM1 / edusecH1)
MergeTotalHM <- transform(MergeTotalHM, sec2 = edusecM2 / edusecH2)
MergeTotalHM <- transform(MergeTotalHM, sec3 = edusecM3 / edusecH3)
MergeTotalHM <- transform(MergeTotalHM, ter1 = eduterM1 / eduterH1)
MergeTotalHM <- transform(MergeTotalHM, ter2 = eduterM2 / eduterH2)
MergeTotalHM <- transform(MergeTotalHM, ter3 = eduterM3 / eduterH3)
MergeTotalHM <- transform(MergeTotalHM, vul1 = vulM1 / vulH1)
MergeTotalHM <- transform(MergeTotalHM, vul2 = vulM2 / vulH2)
MergeTotalHM <- transform(MergeTotalHM, vul3 = vulM3 / vulH3)
MergeTotalHM <- transform(MergeTotalHM, empleo1 = empleoM1 / empleoH1)
MergeTotalHM <- transform(MergeTotalHM, empleo2 = empleoM2 / empleoH2)
MergeTotalHM <- transform(MergeTotalHM, empleo3 = empleoM3 / empleoH3)


MergeTotalHM[,c(2:28)] = NULL
```


TABLA CON TODO 
MergeTotalHM: datos porcentuales de mujeres dividido por datos porcentuales de hombres
OpinionTotal: datos de opinion
DataHombres: datos porcentuales de hombres
Datatotal : datos porcentuales de mujeres y ratio en participacion laboral (%)
DataeduGP: data con los gender parity index (secundaria y terciaria)
```{r}
DataIntegrada=merge(Datatotal, DataHombres,by.x = 'Pais', by.y = 'Pais')
DataCompleta=merge(DataIntegrada, MergeTotalHM,by.x = 'Pais', by.y = 'Pais')
TheData=merge(DataCompleta, OpinionTotal,by.x = 'Pais', by.y = 'Pais')
Data=merge(TheData, DataeduGP,by.x = 'Pais', by.y = 'Pais')
```


```{r}
DATA=Data
DataCluster=DATA[,c(1,2,3,4,5,6,7,8,9,10,14,15,16,17,18,19)]
DataCluster=na.omit(DataCluster)

```



AFE con EmpleoM1,Labor1, edusecM1, EduterM1 por lustros 
Lustro 1
```{r}
library(polycor)
corMatrix1=polycor::hetcor(DataCluster[,c(5,8,11,14)])$correlations 
corMatrix1
#explorar contenidos
library(ggplot2)
library(ggcorrplot)
ggcorrplot(corMatrix1)
```

```{r}
#Evaluando significancia
ggcorrplot(corMatrix1,
           p.mat = cor_pmat(corMatrix1),
           insig = "blank")

#Verificar si puedo factorizar
library(psych)
psych::KMO(corMatrix1) #KMO = 0.49
```

```{r}
#Hnula: La matriz de correlacion es una matriz identidad 
cortest.bartlett(corMatrix1,n=nrow(DataCluster[,c(5,8,11,14)]))$p.value>0.05 #False

#Hnula: La matriz de correlacion es una matriz singular.
library(matrixcalc)
is.singular.matrix(corMatrix1) #False

#Determinando con cuanntos factores podemos redimensionar
fa.parallel(DataCluster[,c(5,8,11,14)],fm = 'ML', fa = 'fa') #2 factores 
#Redimencionando
library(GPArotation) #Colocar el numero de factores 
resfa1 = fa(DataCluster[,c(5,8,11,14)],nfactors = 2,
            cor = 'mixed',
            rotate = "varimax",fm="minres")
print(resfa1$loadings)

#Resultado mejorado
print(resfa1$loadings,cutoff = 0.5)
#Diagrama visual
fa.diagram(resfa1)
```

```{r}
#EVALUACION......
#La Raiz del error cuadratico medio corregida debe estar cerca a 0 
resfa1$crms  #
#La Raiz del error cuadrático medio de aproximacion debe ser menor a 0.05
resfa1$RMSEA  #
#El indice de Tucker-Lewis es mayor a 0.9:
resfa1$TLI  #Cumple


Score1=cbind(DataCluster[1],as.data.frame(resfa1$scores))
names(Score1) = c("Pais", "MREmpleo1","MREdu1")
```

AFE con EmpleoM2,Labor2, edusecM2, EduterM2
```{r}
library(polycor)
corMatrix2=polycor::hetcor(DataCluster[,c(6,9,12,15)])$correlations 
corMatrix2
#explorar contenidos
library(ggplot2)
library(ggcorrplot)
ggcorrplot(corMatrix2)

#Evaluando significancia
ggcorrplot(corMatrix2,
           p.mat = cor_pmat(corMatrix2),
           insig = "blank")
```

```{r}
#Verificar si puedo factorizar
library(psych)
psych::KMO(corMatrix2) #KMO = 0.5
```

```{r}
#Hnula: La matriz de correlacion es una matriz identidad 
cortest.bartlett(corMatrix2,n=nrow(DataCluster[,c(6,9,12,15)]))$p.value>0.05 #False

#Hnula: La matriz de correlacion es una matriz singular.
library(matrixcalc)
is.singular.matrix(corMatrix2) #False

#Determinando con cuanntos factores podemos redimensionar
fa.parallel(DataCluster[,c(6,9,12,15)],fm = 'ML', fa = 'fa') #2 factores 
#Redimencionando
library(GPArotation) #Colocar el numero de factores 
resfa2 = fa(DataCluster[,c(6,9,12,15)],nfactors = 2,
            cor = 'mixed',
            rotate = "varimax",fm="minres")
print(resfa2$loadings)

#Resultado mejorado
print(resfa2$loadings,cutoff = 0.5)
#Diagrama visual
fa.diagram(resfa2)

```

```{r}
#EVALUACION......
#La Raiz del error cuadratico medio corregida debe estar cerca a 0 
resfa2$crms  #NA
#La Raiz del error cuadrático medio de aproximacion debe ser menor a 0.05
resfa2$RMSEA  #NULL
#El indice de Tucker-Lewis es mayor a 0.9:
resfa2$TLI  #Cumple


Score2=cbind(DataCluster[1],as.data.frame(resfa2$scores))
names(Score2) = c("Pais", "MREmpleo2","MREdu2")

```

AFE con EmpleoM3,Labor3, edusecM3, EduterM3

```{r}
library(polycor)
corMatrix3=polycor::hetcor(DataCluster[,c(7,10,13,16)])$correlations 
corMatrix3
#explorar contenidos
library(ggplot2)
library(ggcorrplot)
ggcorrplot(corMatrix3)

```

```{r}
#Evaluando significancia
ggcorrplot(corMatrix3,
           p.mat = cor_pmat(corMatrix3),
           insig = "blank")

#Verificar si puedo factorizar
library(psych)
psych::KMO(corMatrix3) #KMO = 0.5
```

```{r}
#Hnula: La matriz de correlacion es una matriz identidad 
cortest.bartlett(corMatrix3,n=nrow(DataCluster[,c(7,10,13,16)]))$p.value>0.05 #False

#Hnula: La matriz de correlacion es una matriz singular.
library(matrixcalc)
is.singular.matrix(corMatrix3) #False

#Determinando con cuanntos factores podemos redimensionar
fa.parallel(DataCluster[,c(7,10,13,16)],fm = 'ML', fa = 'fa') #2 factores 
#Redimencionando
library(GPArotation) #Colocar el numero de factores 
resfa3 = fa(DataCluster[,c(7,10,13,16)],nfactors = 2,
            cor = 'mixed',
            rotate = "varimax",fm="minres")
print(resfa3$loadings)

#Resultado mejorado
print(resfa3$loadings,cutoff = 0.5)
#Diagrama visual
fa.diagram(resfa3)

```

```{r}
#EVALUACION......
#La Raiz del error cuadratico medio corregida debe estar cerca a 0 
resfa3$crms  #NA
#La Raiz del error cuadrático medio de aproximacion debe ser menor a 0.05
resfa3$RMSEA  #NULL
#El indice de Tucker-Lewis es mayor a 0.9:
resfa3$TLI  #Cumple

resfa3$complexity
Score3=cbind(DataCluster[1],as.data.frame(resfa3$scores))
names(Score3) = c("Pais", "MREmpleo3","MREdu3")
```

Nuestra data con las variables latentes
```{r}
DATA=merge(Data,Score1,by.x='Pais', by.y='Pais')
DATA=merge(DATA,Score2,by.x='Pais', by.y='Pais')
DATA=merge(DATA,Score3,by.x='Pais', by.y='Pais')
```



REGRESION PARA EL PRIMER LUSTRO
```{r}
library(stargazer)
gol1= formula(deparla1 ~ MREmpleo1 + MREdu1)
regol1=lm(gol1,data=DATA)
stargazer(regol1,type = "text",intercept.bottom = FALSE)
summary(regol1)

```

Requisitos /evaluacion de la regresion lustro 1

```{r}
#regresion pruebas
#1
#Pruebas
#Linealidad
plot(regol1, 1)

#Homocedasticidad
library(lmtest)
bptest(regol1)
#H0 Los datos son homocedásticos
#Debe ser menor que 0.05 para rechazar la hipotesis O

#Normalidad de residuos
#H0=La población se distribuye normalmente
shapiro.test(regol1$residuals)

#La regresión no tiene a sus residuos distribuidos normalmente.
plot(regol1, 2)

#No multicolinealidad
library(DescTools)
VIF(regol1)
#Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad
#>5 no es deseable

#Valores influyentes
checkregol1=as.data.frame(influence.measures(regol1)$is.inf)
checkregol1[checkregol1$cook.d | checkregol1$hat,]
plot(regol1, 5)


```

REGRESION PARA EL SEGUNDO LUSTRO
```{r}
gol2= formula(deparla2 ~ MREmpleo2 + MREdu2)
regol2=lm(gol2,data=DATA)
stargazer(regol2,type = "text",intercept.bottom = FALSE)
summary(regol2)
```

REQUISITOS/PRUEBAS SEGUNDO LUSTRO
```{r}
#2
#Pruebas
#Linealidad
plot(regol2, 1)

#Homocedasticidad
library(lmtest)
bptest(regol2)
#H0 Los datos son homocedásticos
#Debe ser menor que 0.05 para rechazar la hipotesis O

#Normalidad de residuos
#H0=La población se distribuye normalmente
shapiro.test(regol2$residuals)

#La regresión no tiene a sus residuos distribuidos normalmente.
plot(regol2, 2)

#No multicolinealidad
library(DescTools)
VIF(regol2)
#Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad
#>5 no es deseable

#Valores influyentes
checkregol2=as.data.frame(influence.measures(regol2)$is.inf)
checkregol2[checkregol2$cook.d | checkregol2$hat,]
plot(regol2, 5)

```


REGRESION PARA EL TERCER LUSTRO
```{r}
gol3= formula(dparla3 ~ MREmpleo3 + MREdu3)
regol3=lm(gol3,data=DATA)
stargazer(regol3,type = "text",intercept.bottom = FALSE)
summary(regol3)
```

REQUISITOS / PRUEBAS DE LUSTRO 3
```{r}
#3
#Pruebas
#Linealidad
plot(regol3, 1)

#Homocedasticidad

library(lmtest)
bptest(regol3)
#H0 Los datos son homocedásticos
#Debe ser menor que 0.05 para rechazar la hipotesis O

#Normalidad de residuos
#H0=La población se distribuye normalmente
shapiro.test(regol3$residuals)

#La regresión no tiene a sus residuos distribuidos normalmente.
plot(regol3, 2)

#No multicolinealidad
library(DescTools)
VIF(regol3)
#Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad
#>5 no es deseable

#Valores influyentes
checkregol3=as.data.frame(influence.measures(regol3)$is.inf)
checkregol3[checkregol3$cook.d | checkregol3$hat,]
plot(regol3, 5)


```

CLUSTERS POR LUSTRO 
empleoM1, labor1, edusecM1, eduterM1 y la dependiente (dparla)
```{r}


lustro1 = DataCluster[,c(1,2,5,8,11,14)]
lustro2 = DataCluster[,c(1,3,6,9,12,15)]
lustro3 = DataCluster[,c(1,4,7,10,13,16)]



row.names(lustro1)=lustro1$Pais
lustro1$Pais = NULL
row.names(lustro2)=lustro2$Pais
lustro2$Pais = NULL
row.names(lustro3)=lustro3$Pais
lustro3$Pais = NULL

lustro1 = na.omit(lustro1)
lustro2 = na.omit(lustro2)
lustro3 = na.omit(lustro3)

library(cluster)
distancia1 = daisy(lustro1[,c(1:5)], metric="gower")
distancia2 = daisy(lustro2[,c(1:5)], metric="gower")
distancia3 = daisy(lustro3[,c(1:5)], metric="gower")
```


PAM
```{r}
library(factoextra)
fviz_nbclust(lustro1[,c(1:5)], pam,diss=distancia1,method = "gap_stat",k.max = 10,verbose = F)
#recomienda:4
fviz_nbclust(lustro2[,c(1:5)], pam,diss=distancia2,method = "gap_stat",k.max = 10,verbose = F)
#recomienda:4
fviz_nbclust(lustro3[,c(1:5)], pam,diss=distancia3,method = "gap_stat",k.max = 10,verbose = F)
#recomienda:4
```

```{r}
pam.resultadoN1=pam(distancia1,4,cluster.only = F)
lustro1$clusterPam=pam.resultadoN1$cluster
fviz_cluster(object = list(data=distancia1, cluster = lustro1$clusterPam),
             geom = c("text"), 
             ellipse.type = "convex")

pam.resultadoN2=pam(distancia2,4,cluster.only = F)
lustro2$clusterPam=pam.resultadoN2$cluster
fviz_cluster(object = list(data=distancia2, cluster = lustro2$clusterPam),
             geom = c("text"), 
             ellipse.type = "convex")

pam.resultadoN3=pam(distancia3,4,cluster.only = F)
lustro3$clusterPam=pam.resultadoN3$cluster
fviz_cluster(object = list(data=distancia3, cluster = lustro3$clusterPam),
             geom = c("text"), 
             ellipse.type = "convex")
```



PARA AGNES Y DIANA 

```{r}
fviz_nbclust(lustro1[,c(1:5)], hcut,diss=distancia1,method = "gap_stat",k.max = 10,verbose = F)
#recomienda:4
fviz_nbclust(lustro2[,c(1:5)], hcut,diss=distancia2,method = "gap_stat",k.max = 10,verbose = F)
#recomienda:5
fviz_nbclust(lustro3[,c(1:5)], hcut,diss=distancia3,method = "gap_stat",k.max = 10,verbose = F)
#recomienda:4
```

AGNES:
```{r}
res.agnesN1 = hcut(distancia1, k=4, hc_func = 'agnes',hc_method = "ward.D")
lustro1$clusterAG = res.agnesN1$cluster
fviz_dend(res.agnesN1, cex=0.7, horiz = F)

res.agnesN2 = hcut(distancia2, k=4, hc_func = 'agnes',hc_method = "ward.D")
lustro2$clusterAG = res.agnesN2$cluster
fviz_dend(res.agnesN2, cex=0.7, horiz = F)

res.agnesN3 = hcut(distancia3, k=4, hc_func = 'agnes',hc_method = "ward.D")
lustro3$clusterAG = res.agnesN3$cluster
fviz_dend(res.agnesN3, cex=0.7, horiz = F)
```

DIANA: DIANA ES LA MEJOR!!!!!!!!!!
```{r}
res.dianaN1 = hcut(distancia1, k=4, hc_func = 'diana')
lustro1$clusterDIV = res.dianaN1$cluster
fviz_dend(res.dianaN1, cex=0.7, horiz = F)

res.dianaN2 = hcut(distancia2, k=4, hc_func = 'diana')
lustro2$clusterDIV = res.dianaN2$cluster
fviz_dend(res.dianaN2, cex=0.7, horiz = F)

res.dianaN3 = hcut(distancia3, k=4, hc_func = 'diana')
lustro3$clusterDIV = res.dianaN3$cluster
fviz_dend(res.dianaN3, cex=0.7, horiz = F)
```



COMPARACION DE MODELOS PAM 
```{r}
fviz_silhouette(pam.resultadoN1) #0.34
fviz_silhouette(pam.resultadoN2) #0.33
fviz_silhouette(pam.resultadoN3)#0.34
```

COMPARACION DE MODELOS AGNES
```{r}
fviz_silhouette(res.agnesN1)
fviz_silhouette(res.agnesN2)
fviz_silhouette(res.agnesN3)

```
COMPARACION MODELOS DIANA
```{r}
fviz_silhouette(res.dianaN1)
fviz_silhouette(res.dianaN2)
fviz_silhouette(res.dianaN3)
```

MAL ASIGNADOS PAM
```{r}
poorPAM1=data.frame(pam.resultadoN1$silinfo$widths)
poorPAM1$Country=row.names(poorPAM1)
poorPAM1cases=poorPAM1[poorPAM1$sil_width<0, "Country"]
poorPAM1cases

poorPAM2=data.frame(pam.resultadoN2$silinfo$widths)
poorPAM2$Country=row.names(poorPAM2)
poorPAM2cases=poorPAM2[poorPAM2$sil_width<0, "Country"]
poorPAM2cases

poorPAM3=data.frame(pam.resultadoN3$silinfo$widths)
poorPAM3$Country=row.names(poorPAM3)
poorPAM3cases=poorPAM3[poorPAM3$sil_width<0, "Country"]
poorPAM3cases

length(poorPAM3cases)
length(poorPAM1cases)
length(poorPAM2cases)
```

```{r}
poorAG1=data.frame(res.agnesN1$silinfo$widths)
poorAG1$Country=row.names(poorAG1)
poorAG1cases=poorAG1[poorAG1$sil_width<0, "Country"]
poorAG1cases

poorAG2=data.frame(res.agnesN2$silinfo$widths)
poorAG2$Country=row.names(poorAG2)
poorAG2cases=poorAG2[poorAG2$sil_width<0, "Country"]
poorAG2cases

poorAG3=data.frame(res.agnesN3$silinfo$widths)
poorAG3$Country=row.names(poorAG3)
poorAG3cases=poorAG3[poorPAM3$sil_width<0, "Country"]
poorAG3cases

length(poorAG3cases)
length(poorAG2cases)
length(poorAG1cases)
```

```{r}
poorDI1=data.frame(res.dianaN1$silinfo$widths)
poorDI1$Country=row.names(poorDI1)
poorDI1cases=poorDI1[poorDI1$sil_width<0, "Country"]
poorDI1cases

poorDI2=data.frame(res.dianaN2$silinfo$widths)
poorDI2$Country=row.names(poorDI2)
poorDI2cases=poorDI2[poorDI2$sil_width<0, "Country"]
poorDI2cases

poorDI3=data.frame(res.dianaN3$silinfo$widths)
poorDI3$Country=row.names(poorDI3)
poorDI3cases=poorDI3[poorDI3$sil_width<0, "Country"]
poorDI3cases

length(poorDI1cases)
length(poorDI2cases)
length(poorDI3cases)
```

TABLAS RESUMEN DEL MODELO SELECCIONADO : DIANA PARA VER EL CAMBIO A TRAVES DE LOS ANOS Y EL CRITERIO DE AGRUPACION
```{r}
library(plyr) # para funcion "each"..


# guardando resultado anterior en objeto "agg": 
agg=aggregate(as.matrix(cbind(lustro1[,c(1:5)]))~ clusterDIV, 
              data=lustro1, # luego las funciones que deseas
              FUN=plyr::each(MD = median, Media = mean))

# convertir en data frame, y 
tablaResumenDI1=t(as.data.frame(agg))
tablaResumenDI1
```



```{r}
library(plyr) # para funcion "each"..


# guardando resultado anterior en objeto "agg": 
agg2=aggregate(as.matrix(cbind(lustro2[,c(1:5)]))~ clusterDIV, 
              data=lustro2, # luego las funciones que deseas
              FUN=plyr::each(MD = median, Media = mean))

# convertir en data frame, y 
tablaResumenDI2=t(as.data.frame(agg2))
tablaResumenDI2
```


```{r}
library(plyr) # para funcion "each"..


# guardando resultado anterior en objeto "agg": 
agg3=aggregate(as.matrix(cbind(lustro3[,c(1:5)]))~ clusterDIV, 
              data=lustro3, # luego las funciones que deseas
              FUN=plyr::each(MD = median, Media = mean))

# convertir en data frame, y 
tablaResumenDI3=t(as.data.frame(agg3))
tablaResumenDI3
```


ANALISIS FACTORIAL TOTAL
AFE con EmpleoM,Labor, edusecM, EduterM
```{r}
library(polycor)
TODOMATRIZ=polycor::hetcor(DataCluster[,c(5:16)])$correlations 
TODOMATRIZ
#explorar contenidos
library(ggplot2)
library(ggcorrplot)
ggcorrplot(TODOMATRIZ)
```

```{r}
#Evaluando significancia
ggcorrplot(TODOMATRIZ,
           p.mat = cor_pmat(TODOMATRIZ),
           insig = "blank")

#Verificar si puedo factorizar
library(psych)
psych::KMO(TODOMATRIZ) #KMO = 0.75
```


```{r}
#Hnula: La matriz de correlacion es una matriz identidad 
cortest.bartlett(TODOMATRIZ,n=nrow(DataCluster[,c(5:16)]))$p.value>0.05 #False

#Hnula: La matriz de correlacion es una matriz singular.
library(matrixcalc)
is.singular.matrix(TODOMATRIZ) #true

```

Nos recomendo dimensionar en 2 latentes
```{r}
#Determinando con cuanntos factores podemos redimensionar
fa.parallel(DataCluster[,c(5:16)],fm = 'ML', fa = 'fa') #2 factores 
#Redimencionando
library(GPArotation) #Colocar el numero de factores 
AFETOT = fa(DataCluster[,c(5:16)],nfactors = 2,
            cor = 'mixed',
            rotate = "varimax",fm="minres")
print(AFETOT$loadings)
#Resultado mejorado
print(AFETOT$loadings,cutoff = 0.5)
#Diagrama visual
fa.diagram(AFETOT)

```
```{r}
AFETOT$complexity
```


```{r}
#EVALUACION......
#La Raiz del error cuadratico medio corregida debe estar cerca a 0 
AFETOT$crms  #0.030
#La Raiz del error cuadrático medio de aproximacion debe ser menor a 0.05
AFETOT$RMSEA  #No cumple
#El indice de Tucker-Lewis es mayor a 0.9:
AFETOT$TLI  #no Cumple


afetot=cbind(DataCluster[1],as.data.frame(AFETOT$scores))
names(afetot) = c("Pais", "mrempleo","mreduM")

```

hacemos el merge de nuestras latentes e incluimos la variable dependiente.
Se ha sacado promedio de los 3 lustros de la dependiente para que sea una sola 
columna
```{r}
TOTO=merge(DataCluster,afetot,by.x='Pais', by.y='Pais')
##REGRESION total con promedio lustros 
TOTO$"promlustros" = rowMeans(TOTO[, 2:4], na.rm=TRUE)

```

REGRESION TOTAL
```{r}
library(stargazer)
tot= formula(promlustros ~ mrempleo + mreduM)
retot=lm(tot,data=TOTO)
stargazer(retot,type = "text",intercept.bottom = FALSE)
summary(retot)

```
 
PRUEBAS Y REQUISITOS DE LA REGRESION TOTAL
```{r}
#total
#Pruebas
#Linealidad
plot(retot, 1)

#Homocedasticidad
library(lmtest)
bptest(retot)
#H0 Los datos son homocedásticos
#Debe ser menor que 0.05 para rechazar la hipotesis O

#Normalidad de residuos
#H0=La población se distribuye normalmente
shapiro.test(retot$residuals)

#La regresión no tiene a sus residuos distribuidos normalmente.
plot(retot, 2)

#No multicolinealidad
library(DescTools)
VIF(retot)
#Si los predictores tienen una correlación muy alta entre sí, hay multicolinealidad
#>5 no es deseable

#Valores influyentes
checkretot=as.data.frame(influence.measures(retot)$is.inf)
checkretot[checkretot$cook.d | checkretot$hat,]
plot(retot, 5)
```

CLUSTERIZACION DE TOTAL


```{r}
DataTOT=DataCluster
row.names(DataTOT)=DataTOT$Pais
DataTOT$Pais = NULL

#nube = na.omit(nube)

library(cluster)
dist.total = daisy(DataTOT, metric="gower")
```

pam
```{r}
library(factoextra)
fviz_nbclust(DataTOT, pam,diss=dist.total,method = "gap_stat",k.max = 10,verbose = F) 
#recomienda 7
```

```{r}
pam.resultadotot=pam(dist.total,7,cluster.only = F)
DataTOT$clusterPam=pam.resultadotot$cluster
fviz_cluster(object = list(data=dist.total, cluster = DataTOT$clusterPam),
             geom = c("text"), 
             ellipse.type = "convex")
```

agnes y diana
```{r}
fviz_nbclust(DataTOT, hcut,diss=dist.total,method = "gap_stat",k.max = 10,verbose = F) #recomienda 4
```

```{r}
res.agnestotal = hcut(dist.total, k=4, hc_func = 'agnes',hc_method = "ward.D")
DataTOT$clusterAG = res.agnestotal$cluster
fviz_dend(res.agnestotal, cex=0.7, horiz = F)
```

COMPARANDO MODELOS
VEMOS QUE DIANA ES MAS ADECUADA
```{r}
res.dianatotal = hcut(dist.total, k=4, hc_func = 'diana')
DataTOT$clusterDIV = res.dianatotal$cluster
fviz_dend(res.dianatotal , cex=0.7, horiz = F)

```


